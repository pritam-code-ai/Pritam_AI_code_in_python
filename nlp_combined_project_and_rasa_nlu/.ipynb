{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz#egg=en_core_web_md==2.0.0 in c:\\users\\home\\anaconda2\\envs\\tensorflow\\lib\\site-packages (2.0.0)\n",
      "symbolic link created for C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\spacy\\data\\en_core_web_md <<===>> C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\en_core_web_md\n",
      "\n",
      "    Linking successful\n",
      "    C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\en_core_web_md\n",
      "    -->\n",
      "    C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\spacy\\data\\en_core_web_md\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_md')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: spacy link [-h] [-f] origin link_name [model_path]\n",
      "spacy link: error: unrecognized arguments: --force;\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# as well as install a language model:\n",
    "!{python} -m spacy download en_core_web_md\n",
    "!{python} -m spacy link en_core_web_md en --force;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rasa_nlu: 0.11.5 rasa_core: 0.10.3\n",
      "Loading spaCy language model...\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy\n",
    "\n",
    "print(\"rasa_nlu: {} rasa_core: {}\".format(rasa_nlu.__version__, rasa_core.__version__))\n",
    "print(\"Loading spaCy language model...\")\n",
    "print(spacy.load(\"en\")(\"Hello world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:mood_affirm\n",
    "- yes\n",
    "- indeed\n",
    "- of course\n",
    "- that sounds good\n",
    "- correct\n",
    "\n",
    "## intent:mood_deny\n",
    "- no\n",
    "- never\n",
    "- I don't think so\n",
    "- don't like that\n",
    "- no way\n",
    "- not really\n",
    "\n",
    "## intent:mood_great\n",
    "- perfect\n",
    "- very good\n",
    "- great\n",
    "- amazing\n",
    "- feeling like a king\n",
    "- wonderful\n",
    "- I am feeling very good\n",
    "- I am great\n",
    "- I am amazing\n",
    "- I am going to save the world\n",
    "- super\n",
    "- extremely good\n",
    "- so so perfect\n",
    "- so good\n",
    "- so perfect\n",
    "\n",
    "## intent:mood_unhappy\n",
    "- my day was horrible\n",
    "- I am sad\n",
    "- I don't feel very well\n",
    "- I am disappointed\n",
    "- super sad\n",
    "- I'm so sad\n",
    "- sad\n",
    "- very sad\n",
    "- unhappy\n",
    "- bad\n",
    "- very bad\n",
    "- awful\n",
    "- terrible\n",
    "- not so good\n",
    "- not very good\n",
    "- extremly sad\n",
    "- so saad\n",
    "- Quite bad - can I get a cute picture of a [bird](group:birds), please?\n",
    "- Really bad and only [doggo](group:shibes) pics and change that.\n",
    "- Not good. The only thing that could make me fell better is a picture of a cute [kitten](group:cats).\n",
    "- so sad. Only the picture of a [puppy](group:shibes) could make it better.\n",
    "- I am very sad. I need a [cat](group:cats) picture.\n",
    "- Extremely sad. Only the cute [doggo](group:shibes) pics can make me feel better.\n",
    "- Bad. Please show me a [bird](group:birds) pic!\n",
    "- Pretty bad to be honest. Can you show me a [puppy](group:shibes) picture to make me fell better?\n",
    "\n",
    "## intent: inform\n",
    "- A [dog](group:shibes)\n",
    "- [dog](group:shibes)\n",
    "- [bird](group:birds)\n",
    "- a [cat](group:cats)\n",
    "- [cat](group:cats)\n",
    "- a [bird](group:birds)\n",
    "- of a [dog](group:shibes)\n",
    "- of a [cat](group:cats)\n",
    "- a [bird](group:birds), please\n",
    "- a [dog](group:shibes), please\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'config.json'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "{\n",
    "\"language\": \"en\", \n",
    "\"pipeline\": \"spacy_sklearn\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "%store config > config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'config.json'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "{\n",
    "\"language\": \"en\", \n",
    "\"pipeline\": \"spacy_sklearn\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "%store config > config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.converters:Training data format at nlu.md is md\n",
      "INFO:rasa_nlu.training_data:Training data stats: \n",
      "\t- intent examples: 85 (7 distinct intents)\n",
      "\t- found intents: 'goodbye', 'greet', 'inform', 'mood_affirm', 'mood_deny', 'mood_great', 'mood_unhappy'\n",
      "\t- entity examples: 18 (1 distinct entities)\n",
      "\t- found entities: 'group'\n",
      "\n",
      "INFO:rasa_nlu.utils.spacy_utils:Trying to load spacy model with name 'en'\n",
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:rasa_nlu.model:Starting to train component nlp_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component tokenizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_featurizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_entity_featurizer_regex\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_crf\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_synonyms\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_classifier_sklearn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.2s finished\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into 'C:\\Users\\Home\\nlp_combined_project\\models\\nlu\\default\\current'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.converters import load_data\n",
    "from rasa_nlu.config import RasaNLUConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu.model import Metadata, Interpreter\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data('nlu.md')\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(RasaNLUConfig('config.json'))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': {'name': 'mood_unhappy', 'confidence': 0.4413529340033879}, 'entities': [{'start': 40, 'end': 43, 'value': 'shibes', 'entity': 'group', 'extractor': 'ner_crf', 'processors': ['ner_synonyms']}], 'intent_ranking': [{'name': 'mood_unhappy', 'confidence': 0.4413529340033879}, {'name': 'mood_great', 'confidence': 0.14306296298493912}, {'name': 'goodbye', 'confidence': 0.1307660850133933}, {'name': 'inform', 'confidence': 0.12679530013616452}, {'name': 'greet', 'confidence': 0.08124976802938856}, {'name': 'mood_affirm', 'confidence': 0.05330003972486289}, {'name': 'mood_deny', 'confidence': 0.02347291010786355}], 'text': 'I am sad, plased send me a picture of a dog'}\n"
     ]
    }
   ],
   "source": [
    "print(interpreter.parse(\"I am sad, plased send me a picture of a dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasa_nlu.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasa_core.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "print(\"-----------------------------------------------------------------\\n\\n\")\n",
    "while True:\n",
    "    \n",
    "    print(\"\\n\\n user: \") \n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "        \n",
    "    print(\"\\n\\n chatbot agent: \") \n",
    "    responses = input()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-27 11:55:55.404 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): files.deeppavlov.ai\n",
      "2019-01-27 11:55:55.796 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://files.deeppavlov.ai:80 \"GET /deeppavlov_data/classifiers/intents_snips_v9.tar.gz.md5 HTTP/1.1\" 200 190\n",
      "2019-01-27 11:55:55.892 INFO in 'deeppavlov.download'['download'] at line 115: Skipped http://files.deeppavlov.ai/deeppavlov_data/classifiers/intents_snips_v9.tar.gz download because of matching hashes\n",
      "2019-01-27 11:55:55.897 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): files.deeppavlov.ai\n",
      "2019-01-27 11:55:56.292 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://files.deeppavlov.ai:80 \"GET /datasets/snips_intents/train.csv.md5 HTTP/1.1\" 200 44\n",
      "2019-01-27 11:55:56.368 INFO in 'deeppavlov.download'['download'] at line 115: Skipped http://files.deeppavlov.ai/datasets/snips_intents/train.csv download because of matching hashes\n",
      "2019-01-27 11:55:56.373 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): files.deeppavlov.ai\n",
      "2019-01-27 11:55:56.765 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://files.deeppavlov.ai:80 \"GET /deeppavlov_data/embeddings/dstc2_fastText_model.bin.md5 HTTP/1.1\" 200 59\n",
      "2019-01-27 11:56:11.749 INFO in 'deeppavlov.download'['download'] at line 115: Skipped http://files.deeppavlov.ai/deeppavlov_data/embeddings/dstc2_fastText_model.bin download because of matching hashes\n",
      "2019-01-27 11:56:11.789 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from C:\\Users\\Home\\.deeppavlov\\models\\classifiers\\intents_snips_v9\\classes.dict]\n",
      "2019-01-27 11:56:11.900 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 52: [loading fastText embeddings from `C:\\Users\\Home\\.deeppavlov\\downloads\\embeddings\\dstc2_fastText_model.bin`]\n",
      "Using TensorFlow backend.\n",
      "2019-01-27 11:57:20.254 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 303: [initializing `KerasClassificationModel` from saved]\n",
      "2019-01-27 11:57:22.176 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 313: [loading weights from model.h5]\n",
      "2019-01-27 11:57:24.259 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 137: Model was successfully initialized!\n",
      "Model summary:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 256)    25856       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    51456       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    77056       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 256)    1024        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 256)    1024        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 256)    1024        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 256)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 256)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 768)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          76900       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100)          400         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 7)            707         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7)            28          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 7)            0           batch_normalization_5[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 235,475\n",
      "Trainable params: 233,725\n",
      "Non-trainable params: 1,750\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['GetWeather']]\n"
     ]
    }
   ],
   "source": [
    "# Classification models in DeepPavlov\n",
    "\n",
    "from deeppavlov import build_model, configs\n",
    "\n",
    "CONFIG_PATH = configs.classifiers.intents_snips\n",
    "\n",
    "model = build_model(CONFIG_PATH, download=True)\n",
    "\n",
    "print(model([\"What is the weather in Boston today?\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-27 12:18:59.439 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): files.deeppavlov.ai\n",
      "2019-01-27 12:18:59.836 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://files.deeppavlov.ai:80 \"GET /datasets/UD2.0_source/en.tar.gz.md5 HTTP/1.1\" 200 156\n",
      "2019-01-27 12:18:59.851 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): files.deeppavlov.ai\n",
      "2019-01-27 12:19:00.285 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://files.deeppavlov.ai:80 \"GET /datasets/UD2.0_source/en.tar.gz HTTP/1.1\" 200 2617225\n",
      "2019-01-27 12:19:00.295 INFO in 'deeppavlov.core.data.utils'['utils'] at line 64: Downloading from http://files.deeppavlov.ai/datasets/UD2.0_source/en.tar.gz to C:\\Users\\Home\\.deeppavlov\\downloads\\UD2.0_source\\en.tar.gz\n",
      "100%|█████████████████████████████████████| 2.62M/2.62M [00:02<00:00, 1.06MB/s]\n",
      "2019-01-27 12:19:02.791 INFO in 'deeppavlov.core.data.utils'['utils'] at line 202: Extracting C:\\Users\\Home\\.deeppavlov\\downloads\\UD2.0_source\\en.tar.gz archive into C:\\Users\\Home\\.deeppavlov\\downloads\\UD2.0_source\\en\n",
      "2019-01-27 12:19:03.14 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): files.deeppavlov.ai\n",
      "2019-01-27 12:19:03.422 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://files.deeppavlov.ai:80 \"GET /deeppavlov_data/morpho_tagger/UD2.0/en.tar.gz.md5 HTTP/1.1\" 200 132\n",
      "2019-01-27 12:19:03.438 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 208: Starting new HTTP connection (1): files.deeppavlov.ai\n",
      "2019-01-27 12:19:03.881 DEBUG in 'urllib3.connectionpool'['connectionpool'] at line 396: http://files.deeppavlov.ai:80 \"GET /deeppavlov_data/morpho_tagger/UD2.0/en.tar.gz HTTP/1.1\" 200 14315506\n",
      "2019-01-27 12:19:03.886 INFO in 'deeppavlov.core.data.utils'['utils'] at line 64: Downloading from http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/UD2.0/en.tar.gz to C:\\Users\\Home\\.deeppavlov\\models\\morpho_tagger\\UD2.0\\en.tar.gz\n",
      "100%|█████████████████████████████████████| 14.3M/14.3M [00:07<00:00, 1.92MB/s]\n",
      "2019-01-27 12:19:11.385 INFO in 'deeppavlov.core.data.utils'['utils'] at line 202: Extracting C:\\Users\\Home\\.deeppavlov\\models\\morpho_tagger\\UD2.0\\en.tar.gz archive into C:\\Users\\Home\\.deeppavlov\\models\\morpho_tagger\\UD2.0\\en\n",
      "2019-01-27 12:19:11.623 INFO in 'deeppavlov.core.data.vocab'['vocab'] at line 175: [loading vocabulary from C:\\Users\\Home\\.deeppavlov\\models\\morpho_tagger\\UD2.0\\en\\tag.dict]\n",
      "2019-01-27 12:19:11.658 INFO in 'deeppavlov.core.data.vocab'['vocab'] at line 175: [loading vocabulary from C:\\Users\\Home\\.deeppavlov\\models\\morpho_tagger\\UD2.0\\en\\char.dict]\n",
      "2019-01-27 12:19:11.801 INFO in 'deeppavlov.models.morpho_tagger.network'['network'] at line 126: 82 symbols, 119 tags in CharacterTagger\n",
      "2019-01-27 12:19:13.521 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 106: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.531 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "2019-01-27 12:19:13.546 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 108: ==================================================================================================\n",
      "2019-01-27 12:19:13.566 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: input_1 (InputLayer)            (None, None, 32)     0                                            \n",
      "2019-01-27 12:19:13.581 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.586 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: lambda_1 (Lambda)               (None, None, 32, 82) 0           input_1[0][0]                    \n",
      "2019-01-27 12:19:13.616 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.626 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: dense_1 (Dense)                 (None, None, 32, 32) 2624        lambda_1[0][0]                   \n",
      "2019-01-27 12:19:13.641 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.646 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: conv2d_1 (Conv2D)               (None, None, 32, 50) 1650        dense_1[0][0]                    \n",
      "2019-01-27 12:19:13.656 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.661 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: conv2d_2 (Conv2D)               (None, None, 32, 100 6500        dense_1[0][0]                    \n",
      "2019-01-27 12:19:13.666 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.671 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: conv2d_3 (Conv2D)               (None, None, 32, 150 14550       dense_1[0][0]                    \n",
      "2019-01-27 12:19:13.671 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.676 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: conv2d_4 (Conv2D)               (None, None, 32, 200 25800       dense_1[0][0]                    \n",
      "2019-01-27 12:19:13.681 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.686 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: conv2d_5 (Conv2D)               (None, None, 32, 200 32200       dense_1[0][0]                    \n",
      "2019-01-27 12:19:13.686 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.691 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: conv2d_6 (Conv2D)               (None, None, 32, 200 38600       dense_1[0][0]                    \n",
      "2019-01-27 12:19:13.696 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.701 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: conv2d_7 (Conv2D)               (None, None, 32, 200 45000       dense_1[0][0]                    \n",
      "2019-01-27 12:19:13.731 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.731 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: concatenate_1 (Concatenate)     (None, None, 32, 110 0           conv2d_1[0][0]                   \n",
      "2019-01-27 12:19:13.736 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104:                                                                  conv2d_2[0][0]                   \n",
      "2019-01-27 12:19:13.746 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104:                                                                  conv2d_3[0][0]                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-27 12:19:13.746 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104:                                                                  conv2d_4[0][0]                   \n",
      "2019-01-27 12:19:13.751 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104:                                                                  conv2d_5[0][0]                   \n",
      "2019-01-27 12:19:13.756 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104:                                                                  conv2d_6[0][0]                   \n",
      "2019-01-27 12:19:13.756 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104:                                                                  conv2d_7[0][0]                   \n",
      "2019-01-27 12:19:13.761 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.783 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: lambda_2 (Lambda)               (None, None, 1100)   0           concatenate_1[0][0]              \n",
      "2019-01-27 12:19:13.786 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.800 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: highway_1 (Highway)             (None, None, 1100)   2422200     lambda_2[0][0]                   \n",
      "2019-01-27 12:19:13.803 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.806 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: dropout_1 (Dropout)             (None, None, 1100)   0           highway_1[0][0]                  \n",
      "2019-01-27 12:19:13.815 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.820 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: bidirectional_1 (Bidirectional) (None, None, 256)    1258496     dropout_1[0][0]                  \n",
      "2019-01-27 12:19:13.823 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 170: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.828 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 104: p (TimeDistributed)             (None, None, 119)    30583       bidirectional_1[0][0]            \n",
      "2019-01-27 12:19:13.832 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 168: ==================================================================================================\n",
      "2019-01-27 12:19:13.835 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 181: Total params: 3,878,203\n",
      "2019-01-27 12:19:13.838 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 182: Trainable params: 3,878,203\n",
      "2019-01-27 12:19:13.841 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 183: Non-trainable params: 0\n",
      "2019-01-27 12:19:13.845 INFO in 'deeppavlov.models.morpho_tagger.network'['layer_utils'] at line 184: __________________________________________________________________________________________________\n",
      "2019-01-27 12:19:13.848 INFO in 'deeppavlov.core.models.keras_model'['keras_model'] at line 144: [loading model from C:\\Users\\Home\\.deeppavlov\\models\\morpho_tagger\\UD2.0\\en\\model.hdf5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tI\tPRON\tCase=Nom|Number=Sing|Person=1|PronType=Prs\n",
      "2\twas\tAUX\tMood=Ind|Number=Sing|Person=1|Tense=Past|VerbForm=Fin\n",
      "3\twalking\tVERB\tTense=Pres|VerbForm=Part\n",
      "4\thome\tADV\t_\n",
      "5\ton\tADP\t_\n",
      "6\tan\tDET\tDefinite=Ind|PronType=Art\n",
      "7\tunfamiliar\tADJ\tDegree=Pos\n",
      "8\tstreet\tNOUN\tNumber=Sing\n",
      "9\t.\tPUNCT\t_\n",
      "\n",
      "1\tThe\tDET\tDefinite=Def|PronType=Art\n",
      "2\tgirl\tNOUN\tNumber=Sing\n",
      "3\tsang\tNOUN\tNumber=Sing\n",
      "4\tin\tADP\t_\n",
      "5\tthe\tDET\tDefinite=Def|PronType=Art\n",
      "6\tchurch\tNOUN\tNumber=Sing\n",
      "7\tchoir\tNOUN\tNumber=Sing\n",
      "8\tabout\tADP\t_\n",
      "9\tall\tADV\t_\n",
      "10\ttired\tADJ\tDegree=Pos\n",
      "11\tin\tADP\t_\n",
      "12\ta\tDET\tDefinite=Ind|PronType=Art\n",
      "13\tstrange\tADJ\tDegree=Pos\n",
      "14\tland\tNOUN\tNumber=Sing\n",
      "15\t.\tPUNCT\t_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural Morphological Tagging by deeppavlov\n",
    "\n",
    "from deeppavlov import build_model, configs\n",
    "model = build_model(configs.morpho_tagger.UD2_0.morpho_en, download=True)\n",
    "sentences = [\"I was walking home on an unfamiliar street.\", \"The girl sang in the church choir about all tired in a strange land.\"]\n",
    "for parse in model(sentences):\n",
    "    print(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-27 13:25:34.101 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from C:\\Users\\Home\\.deeppavlov\\models\\ner_ontonotes\\tag.dict]\n",
      "2019-01-27 13:25:34.832 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from C:\\Users\\Home\\.deeppavlov\\models\\ner_ontonotes\\char.dict]\n",
      "2019-01-27 13:25:35.325 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `C:\\Users\\Home\\.deeppavlov\\downloads\\embeddings\\glove.6B.100d.txt`]\n",
      "2019-01-27 13:25:35.511 INFO in 'gensim.models.utils_any2vec'['utils_any2vec'] at line 170: loading projection weights from C:\\Users\\Home\\.deeppavlov\\downloads\\embeddings\\glove.6B.100d.txt\n",
      "2019-01-27 13:25:35.792 DEBUG in 'smart_open.smart_open_lib'['smart_open_lib'] at line 176: {'kw': {}, 'mode': 'rb', 'uri': 'C:\\\\Users\\\\Home\\\\.deeppavlov\\\\downloads\\\\embeddings\\\\glove.6B.100d.txt'}\n",
      "2019-01-27 13:26:38.349 INFO in 'gensim.models.utils_any2vec'['utils_any2vec'] at line 232: loaded (400000, 100) matrix from C:\\Users\\Home\\.deeppavlov\\downloads\\embeddings\\glove.6B.100d.txt\n",
      "2019-01-27 13:26:51.702 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-01-27 13:26:53.472 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2019-01-27 13:26:59.528 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 47: [loading model from C:\\Users\\Home\\.deeppavlov\\models\\ner_ontonotes\\model]\n",
      "2019-01-27 13:27:00.20 INFO in 'tensorflow'['tf_logging'] at line 110: Restoring parameters from C:\\Users\\Home\\.deeppavlov\\models\\ner_ontonotes\\model\n",
      "2019-01-27 13:27:00.470 ERROR in 'deeppavlov.core.common.params'['params'] at line 106: Exception in <class 'deeppavlov.models.ner.network.NerNetwork'>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1350, in _do_call\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1329, in _run_fn\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 473, in __exit__\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: Key LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/cudnn_lstm/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel not found in checkpoint\n",
      "\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\common\\params.py\", line 100, in from_params\n",
      "    component = cls(**dict(config_params, **kwargs))\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 74, in __call__\n",
      "    obj.__init__(*args, **kwargs)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 27, in _wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\models\\ner\\network.py\", line 168, in __init__\n",
      "    self.load()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 27, in _wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\lr_scheduled_tf_model.py\", line 221, in load\n",
      "    return super().load(exclude_scopes=exclude_scopes)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py\", line 51, in load\n",
      "    saver.restore(self.sess, path)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1686, in restore\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1128, in _run\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1344, in _do_run\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1363, in _do_call\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: Key LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/cudnn_lstm/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel not found in checkpoint\n",
      "\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]\n",
      "\n",
      "Caused by op 'save/RestoreV2_11', defined at:\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-29-e004a057cf1b>\", line 5, in <module>\n",
      "    ner_model = build_model(configs.ner.ner_ontonotes)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\commands\\infer.py\", line 61, in build_model\n",
      "    component = from_params(component_config, mode=mode, serialized=component_serialized)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\common\\params.py\", line 100, in from_params\n",
      "    component = cls(**dict(config_params, **kwargs))\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 74, in __call__\n",
      "    obj.__init__(*args, **kwargs)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 27, in _wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\models\\ner\\network.py\", line 168, in __init__\n",
      "    self.load()\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 27, in _wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\lr_scheduled_tf_model.py\", line 221, in load\n",
      "    return super().load(exclude_scopes=exclude_scopes)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py\", line 50, in load\n",
      "    saver = tf.train.Saver(var_list)\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1239, in __init__\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1248, in build\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1284, in _build\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 765, in _build_internal\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 428, in _AddRestoreOps\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 268, in restore_op\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1113, in restore_v2\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n",
      "  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n",
      "\n",
      "NotFoundError (see above for traceback): Key LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/cudnn_lstm/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel not found in checkpoint\n",
      "\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/cudnn_lstm/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_11', defined at:\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-e004a057cf1b>\", line 5, in <module>\n    ner_model = build_model(configs.ner.ner_ontonotes)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\commands\\infer.py\", line 61, in build_model\n    component = from_params(component_config, mode=mode, serialized=component_serialized)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\common\\params.py\", line 100, in from_params\n    component = cls(**dict(config_params, **kwargs))\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 74, in __call__\n    obj.__init__(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 27, in _wrapped\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\models\\ner\\network.py\", line 168, in __init__\n    self.load()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 27, in _wrapped\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\lr_scheduled_tf_model.py\", line 221, in load\n    return super().load(exclude_scopes=exclude_scopes)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py\", line 50, in load\n    saver = tf.train.Saver(var_list)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1239, in __init__\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1248, in build\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1284, in _build\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 765, in _build_internal\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 428, in _AddRestoreOps\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 268, in restore_op\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1113, in restore_v2\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n\nNotFoundError (see above for traceback): Key LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/cudnn_lstm/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/cudnn_lstm/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-e004a057cf1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeeppavlov\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mner_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mner_ontonotes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mner_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Bob Ross lived in Florida'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\commands\\infer.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(config, mode, load_trained, download, serialized)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mcomponent_serialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserialized\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomponent_serialized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'in'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomponent_config\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\common\\params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[1;34m(params, mode, serialized, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0m_refs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconfig_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[0mwrapped_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_graph_wrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapped_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\u001b[0m in \u001b[0;36m_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\models\\ner\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_tags, token_emb_dim, char_emb_dim, capitalization_dim, pos_features_dim, additional_features, net_type, cell_type, use_cudnn_rnn, two_dense_on_top, n_hidden_list, cnn_filter_width, use_crf, token_emb_mat, char_emb_mat, use_batch_norm, dropout_keep_prob, embeddings_dropout, top_dropout, intra_layer_dropout, l2_reg, gpu, seed, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_training_placeholders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_keep_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\u001b[0m in \u001b[0;36m_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\lr_scheduled_tf_model.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, exclude_scopes)\u001b[0m\n\u001b[0;32m    219\u001b[0m                                                          \u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                                                          'momentum')):\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude_scopes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude_scopes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, exclude_scopes)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_saveable_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude_scopes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/cudnn_lstm/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_11', defined at:\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-e004a057cf1b>\", line 5, in <module>\n    ner_model = build_model(configs.ner.ner_ontonotes)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\commands\\infer.py\", line 61, in build_model\n    component = from_params(component_config, mode=mode, serialized=component_serialized)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\common\\params.py\", line 100, in from_params\n    component = cls(**dict(config_params, **kwargs))\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 74, in __call__\n    obj.__init__(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 27, in _wrapped\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\models\\ner\\network.py\", line 168, in __init__\n    self.load()\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_backend.py\", line 27, in _wrapped\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\lr_scheduled_tf_model.py\", line 221, in load\n    return super().load(exclude_scopes=exclude_scopes)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\deeppavlov\\core\\models\\tf_model.py\", line 50, in load\n    saver = tf.train.Saver(var_list)\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1239, in __init__\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1248, in build\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1284, in _build\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 765, in _build_internal\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 428, in _AddRestoreOps\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 268, in restore_op\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1113, in restore_v2\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n  File \"C:\\Users\\Home\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n\nNotFoundError (see above for traceback): Key LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/cudnn_lstm/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_11 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_11/tensor_names, save/RestoreV2_11/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "#Named Entity Recognition (NER) by deeppavlov\n",
    "\n",
    "from deeppavlov import configs, build_model\n",
    "\n",
    "ner_model = build_model(configs.ner.ner_ontonotes)\n",
    "ner_model(['Bob Ross lived in Florida'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
