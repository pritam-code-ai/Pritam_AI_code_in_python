{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary python libraries \n",
    "\n",
    "import pandas as pd \n",
    "import csv\n",
    "import os \n",
    "import string \n",
    "import xlrd\n",
    "from dateutil.parser import parse\n",
    "import glob\n",
    "import xlsxwriter\n",
    "import numpy as np \n",
    "from scipy import stats \n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'Final_Output.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3f1b8c1102f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final_Output.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabel_unique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlabel_unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'Final_Output.csv' does not exist"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Final_Output.csv', encoding='utf-8')\n",
    "label_unique = data['Label'].unique()\n",
    "label_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col10 = []\n",
    "col_gh = []\n",
    "\n",
    "with open('Final_Output.csv') as f:\n",
    "  for row in csv.reader(f):\n",
    "    col10.append(row[38])\n",
    "\n",
    "label_unique_list = list(label_unique)\n",
    "length_of_label_unique_list = len(label_unique_list)\n",
    "\n",
    "for name in label_unique_list: \n",
    "    find_value = len(col10) - col10[::-1].index(name) - 1\n",
    "    print(find_value)\n",
    "    find_value += 1 \n",
    "    col_gh.append(find_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "i = 0\n",
    "list_store = []\n",
    "df = pd.DataFrame()\n",
    "dataframe_collection = {}\n",
    "gh600 = 0\n",
    "gh300 = []\n",
    "gh_100 = []\n",
    "col1_gh = 0\n",
    "z_index_for_col1 = 0.0\n",
    "column_list = []\n",
    "list_store = []\n",
    "count_gh = 0\n",
    "count_store = []\n",
    "b_for_col1 = 0\n",
    "sum_of_z_1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=preprocessing.LabelEncoder()\n",
    "\n",
    "Nose_x = list(le.fit_transform(data.iloc[ gh600:(gh+1),    2  ]))\n",
    "Nose_y = list(le.fit_transform(data.iloc[   gh600:(gh+1),  3   ]))\n",
    "Neck_x = list(le.fit_transform(data.iloc[  gh600:(gh+1),    4  ]))\n",
    "Neck_y = list(le.fit_transform(data.iloc[  gh600:(gh+1),     5  ]))\n",
    "RShoulder_x = list(le.fit_transform(data.iloc[ gh600:(gh+1),  6    ]))\n",
    "RShoulder_y = list(le.fit_transform(data.iloc[  gh600:(gh+1),  7   ]))\n",
    "RElbow_x = list(le.fit_transform(data.iloc[   gh600:(gh+1),   8 ]))\n",
    "RElbow_y = list(le.fit_transform(data.iloc[   gh600:(gh+1),  9  ]))\n",
    "RWrist_x = list(le.fit_transform(data.iloc[  gh600:(gh+1),   10 ]))\n",
    "RWrist_y = list(le.fit_transform(data.iloc[  gh600:(gh+1),    11 ]))\n",
    "LShoulder_x = list(le.fit_transform(data.iloc[   gh600:(gh+1), 12  ]))\n",
    "LShoulder_y = list(le.fit_transform(data.iloc[   gh600:(gh+1),  13 ]))\n",
    "LElbow_x = list(le.fit_transform(data.iloc[    gh600:(gh+1),14 ]))\n",
    "LElbow_y = list(le.fit_transform(data.iloc[   gh600:(gh+1), 15 ]))\n",
    "LWrist_x = list(le.fit_transform(data.iloc[  gh600:(gh+1),  16 ]))\n",
    "LWrist_y = list(le.fit_transform(data.iloc[  gh600:(gh+1),  17 ]))\n",
    "RHip_x = list(le.fit_transform(data.iloc[   gh600:(gh+1), 18  ]))\n",
    "RHip_y = list(le.fit_transform(data.iloc[   gh600:(gh+1),  19 ]))\n",
    "RKnee_x = list(le.fit_transform(data.iloc[   gh600:(gh+1),  20   ]))\n",
    "RKnee_y = list(le.fit_transform(data.iloc[  gh600:(gh+1),  21  ]))\n",
    "RAnkle_x = list(le.fit_transform(data.iloc[  gh600:(gh+1),  22  ]))\n",
    "RAnkle_y = list(le.fit_transform(data.iloc[ gh600:(gh+1),  23  ]))\n",
    "LHip_x = list(le.fit_transform(data.iloc[   gh600:(gh+1), 24 ]))\n",
    "LHip_y = list(le.fit_transform(data.iloc[  gh600:(gh+1),  25  ]))\n",
    "LKnee_x = list(le.fit_transform(data.iloc[ gh600:(gh+1),  26   ]))\n",
    "LKnee_y = list(le.fit_transform(data.iloc[   gh600:(gh+1), 27 ]))\n",
    "LAnkle_x = list(le.fit_transform(data.iloc[  gh600:(gh+1), 28  ]))\n",
    "LAnkle_y = list(le.fit_transform(data.iloc[  gh600:(gh+1), 29  ]))\n",
    "REye_x = list(le.fit_transform(data.iloc[  gh600:(gh+1), 30  ]))\n",
    "REye_y = list(le.fit_transform(data.iloc[  gh600:(gh+1),  31 ]))\n",
    "LEye_x = list(le.fit_transform(data.iloc[ gh600:(gh+1), 32 ]))\n",
    "LEye_y = list(le.fit_transform(data.iloc[  gh600:(gh+1),  33 ]))\n",
    "REar_x = list(le.fit_transform(data.iloc[ gh600:(gh+1),  34 ]))\n",
    "REar_y = list(le.fit_transform(data.iloc[ gh600:(gh+1),  35 ]))\n",
    "LEar_x = list(le.fit_transform(data.iloc[  gh600:(gh+1), 36 ]))\n",
    "LEar_y = list(le.fit_transform(data.iloc[gh600:(gh+1), 37 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [Nose_x, Nose_y, Neck_x, Neck_y, RShoulder_x, RShoulder_y, RElbow_x, \n",
    "                   RElbow_y, RWrist_x, RWrist_y, LShoulder_x, LShoulder_y, LElbow_x, \n",
    "                   LElbow_y, LWrist_x, LWrist_y, RHip_x, RHip_y, RKnee_x, RKnee_y, RAnkle_x, \n",
    "                   RAnkle_y, LHip_x, LHip_y, LKnee_x, LKnee_y, LAnkle_x, LAnkle_y, REye_x, \n",
    "                   REye_y, LEye_x, LEye_y, REar_x, REar_y, LEar_x, LEar_y]\n",
    "\n",
    "length_of_column_list = len(column_list)\n",
    "print(\"length of column_list = {}\".format(length_of_column_list))\n",
    "        \n",
    "    #for value in (column_list):\n",
    "        \n",
    "        #value = list(map(int, value))\n",
    "        #print(value)\n",
    "value = column_list\n",
    "gggggg = 0\n",
    "value3 = []\n",
    "for l in value:\n",
    "    if l > 0:\n",
    "        value3.append(l)   \n",
    "        continue\n",
    "                \n",
    "positive_value = value3\n",
    "print(positive_value)\n",
    "        #positive_value = value[value > 0]\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_for_col1 = stats.boxcox(positive_value, lmbda=None)\n",
    "b_for_col1 = b_for_col1 * 100\n",
    "#print(\"b_for_col1 = {}\".format(b_for_col1))\n",
    "b_col1 = b_for_col1[1]\n",
    "b_col1 = b_col1 * 100\n",
    "b_col1 = np.round(b_col1)\n",
    "#print(\"b_col1 = {}\".format(b_col1))\n",
    "   \n",
    "\n",
    "col1_median = np.median(positive_value)\n",
    "col1_coefficient_of_variation = stats.variation(positive_value)\n",
    "y_for_col1 = np.average(positive_value)\n",
    "\n",
    "\n",
    "gh1 = ((y_for_col1/col1_median) - 1)\n",
    "gh2 = b_col1\n",
    "col1_L_t_power = np.power(gh1, gh2)\n",
    "g1 = col1_L_t_power\n",
    "g2 = col1_coefficient_of_variation \n",
    "g3 = b_col1\n",
    "multiply_value = np.multiply(g2, g3)\n",
    "z_index_for_col1 = np.divide(g1, multiply_value)\n",
    "z_1 = (z_index_for_col1 * 1000000000000000000000000000000)\n",
    "sum_of_z_1 +=  z_1\n",
    "print(\"z_1 = {}\".format(z_1))\n",
    "\n",
    "#sum_of_z_1 /= length_of_column_list\n",
    "#sum_of_z_1 /= 10000000000000000\n",
    "print(\"z_ind_value = {}\".format(sum_of_z_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
