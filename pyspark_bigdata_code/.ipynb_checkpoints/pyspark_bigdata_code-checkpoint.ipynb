{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import urllib\n",
    "from pyspark import SparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download the ratings.dat and movies.dat files from the mentioned internet site link in the comment and place these in the same folder as this ipynb code file resides. \n",
    "\n",
    "\n",
    "https://raw.githubusercontent.com/databricks/spark-training/master/data/movielens/medium/ratings.dat\n",
    "\n",
    "\n",
    "https://raw.githubusercontent.com/databricks/spark-training/master/data/movielens/medium/movies.dat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPartitions = 2\n",
    "\n",
    "\n",
    "rawRatings = sc.textFile(\"ratings.dat\").repartition(numPartitions)\n",
    "\n",
    "\n",
    "\n",
    "rawMovies = sc.textFile(\"movies.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ratings_tuple(entry):\n",
    "    \"\"\" Parse a line in the ratings dataset\n",
    "    Args:\n",
    "        entry (str): a line in the ratings dataset in the form of UserID::MovieID::Rating::Timestamp\n",
    "    Returns:\n",
    "        tuple: (UserID, MovieID, Rating)\n",
    "    \"\"\"\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), int(items[1]), float(items[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_tuple(entry):\n",
    "    \"\"\" Parse a line in the movies dataset\n",
    "    Args:\n",
    "        entry (str): a line in the movies dataset in the form of MovieID::Title::Genres\n",
    "    Returns:\n",
    "        tuple: (MovieID, Title)\n",
    "    \"\"\"\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsRDD = rawRatings.map(get_ratings_tuple).cache()\n",
    "moviesRDD = rawMovies.map(get_movie_tuple).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsCount = ratingsRDD.count()\n",
    "moviesCount = moviesRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000209 ratings and 3883 movies in the datasets\n",
      "Ratings: [(1, 1193, 5.0), (1, 661, 3.0), (1, 914, 3.0)]\n",
      "Movies: [(1, 'Toy Story (1995)'), (2, 'Jumanji (1995)'), (3, 'Grumpier Old Men (1995)')]\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} ratings and {} movies in the datasets\".format(ratingsCount, moviesCount))\n",
    "print(\"Ratings: {}\".format(ratingsRDD.take(3)))\n",
    "print(\"Movies: {}\".format(moviesRDD.take(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, implement a helper function `getCountsAndAverages` using only Python\n",
    "def getCountsAndAverages(IDandRatingsTuple):\n",
    "    \"\"\" Calculate average rating\n",
    "    Args:\n",
    "        IDandRatingsTuple: a single tuple of (MovieID, (Rating1, Rating2, Rating3, ...))\n",
    "    Returns:\n",
    "        tuple: a tuple of (MovieID, (number of ratings, averageRating))\n",
    "    \"\"\"\n",
    "    result = (IDandRatingsTuple[0], (len(IDandRatingsTuple[1]), float(sum(IDandRatingsTuple[1])) / len(IDandRatingsTuple[1])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieIDsWithRatingsRDD: [(914, <pyspark.resultiterable.ResultIterable object at 0x0000003F8D003E80>), (3408, <pyspark.resultiterable.ResultIterable object at 0x0000003F8D003EB8>), (2804, <pyspark.resultiterable.ResultIterable object at 0x0000003F8D003F60>)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(Movies with Highest Average Ratings)\n",
    "# From ratingsRDD with tuples of (UserID, MovieID, Rating) create an RDD with tuples of\n",
    "# the (MovieID, iterable of Ratings for that MovieID)\n",
    "movieIDsWithRatingsRDD = (ratingsRDD.map(lambda rating: (rating[1], rating[2])).groupByKey())\n",
    "print(\"movieIDsWithRatingsRDD: {}\\n\".format(movieIDsWithRatingsRDD.take(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieIDsWithAvgRatingsRDD: [(914, (636, 4.154088050314465)), (3408, (1315, 3.863878326996198)), (2804, (1352, 4.238905325443787))]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using `movieIDsWithRatingsRDD`, compute the number of ratings and average rating for each movie to\n",
    "# yield tuples of the form (MovieID, (number of ratings, average rating))\n",
    "movieIDsWithAvgRatingsRDD = movieIDsWithRatingsRDD.map(getCountsAndAverages)\n",
    "print(\"movieIDsWithAvgRatingsRDD: {}\\n\".format(movieIDsWithAvgRatingsRDD.take(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieNameWithAvgRatingsRDD: [(2.7294117647058824, 'Waiting to Exhale (1995)', 170), (3.014705882352941, 'Tom and Huck (1995)', 68), (2.3625, 'Dracula: Dead and Loving It (1995)', 160)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To `movieIDsWithAvgRatingsRDD`, apply RDD transformations that use `moviesRDD` to get the movie\n",
    "# names for `movieIDsWithAvgRatingsRDD`, yielding tuples of the form\n",
    "# (average rating, movie name, number of ratings)\n",
    "movieNameWithAvgRatingsRDD = (moviesRDD.join(movieIDsWithAvgRatingsRDD).map(lambda movie: (movie[1][1][1], movie[1][0], movie[1][1][0])))\n",
    "print(\"movieNameWithAvgRatingsRDD: {}\\n\".format(movieNameWithAvgRatingsRDD.take(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with highest ratings: [((4.560509554140127, 'Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)', 628), <pyspark.resultiterable.ResultIterable object at 0x0000003F8C9BF828>), ((4.554557700942973, 'Shawshank Redemption, The (1994)', 2227), <pyspark.resultiterable.ResultIterable object at 0x0000003F8C9BFAC8>), ((4.524966261808367, 'Godfather, The (1972)', 2223), <pyspark.resultiterable.ResultIterable object at 0x0000003F889499E8>), ((4.52054794520548, 'Close Shave, A (1995)', 657), <pyspark.resultiterable.ResultIterable object at 0x0000003F8C9BF5C0>), ((4.517106001121705, 'Usual Suspects, The (1995)', 1783), <pyspark.resultiterable.ResultIterable object at 0x0000003F8C948B00>), ((4.510416666666667, \"Schindler's List (1993)\", 2304), <pyspark.resultiterable.ResultIterable object at 0x0000003F8C948908>), ((4.507936507936508, 'Wrong Trousers, The (1993)', 882), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D018048>), ((4.477724741447892, 'Raiders of the Lost Ark (1981)', 2514), <pyspark.resultiterable.ResultIterable object at 0x0000003F8C9BF400>), ((4.476190476190476, 'Rear Window (1954)', 1050), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D0180B8>), ((4.453694416583082, 'Star Wars: Episode IV - A New Hope (1977)', 2991), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D0180F0>), ((4.4498902706656915, 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 1367), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D018128>), ((4.425646551724138, 'To Kill a Mockingbird (1962)', 928), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D018160>), ((4.415607985480944, 'Double Indemnity (1944)', 551), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D018198>), ((4.412822049131217, 'Casablanca (1942)', 1669), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D0181D0>), ((4.406262708418057, 'Sixth Sense, The (1999)', 2459), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D018208>), ((4.401925391095066, 'Lawrence of Arabia (1962)', 831), <pyspark.resultiterable.ResultIterable object at 0x0000003F8C948AC8>), ((4.395973154362416, 'Maltese Falcon, The (1941)', 1043), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D018278>), ((4.390724637681159, \"One Flew Over the Cuckoo's Nest (1975)\", 1725), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D0182B0>), ((4.388888888888889, 'Citizen Kane (1941)', 1116), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D0182E8>), ((4.386993603411514, 'Bridge on the River Kwai, The (1957)', 938), <pyspark.resultiterable.ResultIterable object at 0x0000003F8D018320>)] \n"
     ]
    }
   ],
   "source": [
    "# Movies with Highest Average Ratings and more than 500 reviews\n",
    "# Apply an RDD transformation to `movieNameWithAvgRatingsRDD` to limit the results to movies with\n",
    "# ratings from more than 500 people. We then use the `sortFunction()` helper function to sort by the\n",
    "# average rating to get the movies in order of their rating (highest rating first)\n",
    "\n",
    "\n",
    "rdd3 = movieNameWithAvgRatingsRDD.filter(lambda movie: movie[2] > 500)\n",
    "rdd3_mapped = rdd3.map(lambda x: (x,1))\n",
    "rdd3_grouped = rdd3_mapped.groupByKey()\n",
    "movieSortedByRating = rdd3_grouped.mapValues(lambda x: x).sortByKey(ascending=False)\n",
    "\n",
    "print(\"Movies with highest ratings: {} \".format(movieSortedByRating.take(20)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
