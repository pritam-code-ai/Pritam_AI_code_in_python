{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from heapq import nlargest\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from heapq import nlargest\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reg_ex(article_paragraph):\n",
    "    article_paragraph = re.sub(re.compile('<.*?>'), ' ', article_paragraph)\n",
    "    article_paragraph = re.sub(r'\\[[0-9]*\\]', ' ', article_paragraph)  \n",
    "    article_paragraph = re.sub(r'\\s+', ' ', article_paragraph) \n",
    "    # Removing special characters and digits\n",
    "    formatted_article = re.sub('[^a-zA-Z]', ' ', article_paragraph)  \n",
    "    formatted_article = re.sub(r'\\s+', ' ', formatted_article) \n",
    "    \n",
    "    #return formatted_article\n",
    "    return article_paragraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "p1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text():\n",
    "    feed_xml = urllib.request.urlopen('https://en.wikipedia.org/wiki/Automatic_summarization').read()\n",
    "    feed = BeautifulSoup(feed_xml.decode('utf8'))\n",
    "    to_summarize = feed.find_all('p')\n",
    "    #print(feed)\n",
    "    article_text = \"\"\n",
    "    i = 0\n",
    "    p1 = []\n",
    "    cc = ''\n",
    "    for p in to_summarize:  \n",
    "        p = reg_ex(str(p))\n",
    "        p1.append(str(p))\n",
    "    \n",
    "    return p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "ggg = get_text()\n",
    "print(len(ggg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_frequency(text):\n",
    "   \n",
    "    word_frequencies = {}  \n",
    "    for word in nltk.word_tokenize(text):  \n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "            \n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "    return word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_scores(sentence, word_frequency):\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence:  \n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequency.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequency[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequency[word]\n",
    "    return sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(sentence_scores_neu, n):\n",
    "    \"\"\" return the first n sentences with highest ranking \"\"\"\n",
    "    return nlargest(n, sentence_scores_neu, key=sentence_scores_neu.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      " Automatic summarization is the process of shortening a text document with software , in order to create a summary with the major points of the original document. Technologies that can make a coherent summary take into account variables such as length, writing style and syntax .\n",
      "--------------------------------------\n",
      "Search engines are an example; others include summarization of documents, image collections and videos. [ citation needed ] For surveillance videos, one might want to extract the important events from the uneventful context. The main idea of summarization is to find a subset of data which contains the \"information\" of the entire set.\n",
      "--------------------------------------\n",
      "In contrast, abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might express. Extractive methods work by selecting a subset of existing words, phrases, or sentences in the original text to form the summary. Research to date has focused primarily on extractive methods, which are appropriate for image collection summarization and video summarization.\n",
      "--------------------------------------\n",
      "Similarly, in image collection summarization, the system extracts images from the collection without modifying the images themselves.  In this summarization task, the automatic system extracts objects from the entire collection, without modifying the objects themselves.\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      " Machine learning techniques from closely related fields such as information retrieval or text mining have been successfully adapted to help automatic summarization.\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "The first is generic summarization , which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization , sometimes called query-based summarization , which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
      "--------------------------------------\n",
      "Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.  An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. A related application is summarizing news articles.\n",
      "--------------------------------------\n",
      "Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Video summarization is a related domain, where the system automatically creates a trailer of a long video.\n",
      "--------------------------------------\n",
      "Some techniques and algorithms which naturally model summarization problems are TextRank and PageRank, Submodular set function , Determinantal point process , maximal marginal relevance (MMR) etc. These algorithms model notions like diversity, coverage, information and representativeness of the summary. Query based summarization techniques, additionally model for relevance of the summary with the query.\n",
      "--------------------------------------\n",
      "In the case of research articles , many authors provide manually assigned keywords, but most text lacks pre-existing keyphrases. For example, news articles rarely have keyphrases attached, but it would be useful to be able to automatically do so for a number of applications discussed below. Consider the example text from a news article:\n",
      "--------------------------------------\n",
      " A keyphrase extractor might select \"Army Corps of Engineers\", \"President Bush\", \"New Orleans\", and \"defective flood-control pumps\" as keyphrases. Abstraction requires a deep understanding of the text , which makes it difficult for a computer system. These are pulled directly from the text.\n",
      "--------------------------------------\n",
      " Depending on the different literature and the definition of key terms, words or phrases, keyword extraction is a highly related theme.\n",
      "--------------------------------------\n",
      "Given a document, we construct an example for each unigram , bigram , and trigram found in the text (though other text units are also possible, as discussed below). For instance, in the above text, we might learn a rule that says phrases with initial capital letters are likely to be keyphrases. The two measures can be combined in an F-score, which is the harmonic mean of the two ( F = 2 PR /( P + R ) ).\n",
      "--------------------------------------\n",
      "For example, if we use only unigrams, bigrams, and trigrams, then we will never be able to extract a known keyphrase containing four words. Ideally, the mechanism for generating examples produces all the known labeled keyphrases as candidates, though this is often not the case. Turney and others have used all possible unigrams, bigrams, and trigrams without intervening punctuation and after removing stopwords.\n",
      "--------------------------------------\n",
      "Hulth uses a reduced set of features, which were found most successful in the KEA (Keyphrase Extraction Algorithm) work derived from Turney’s seminal paper.  We also need to create features that describe the examples and are informative enough to allow a learning algorithm to discriminate keyphrases from non- keyphrases. The Turney paper used about 12 such features.\n",
      "--------------------------------------\n",
      "Ensemble methods (i.e., using votes from several classifiers) have been used to produce numeric scores that can be thresholded to provide a user-provided number of keyphrases.  In the end, the system will need to return a list of keyphrases for a test document, so we need to have a way to limit the number. Hulth used a single binary classifier so the learning algorithm implicitly determines the appropriate number.\n",
      "--------------------------------------\n",
      "In the case of Turney's GenEx algorithm, a genetic algorithm is used to learn parameters for a domain-specific keyphrase extraction algorithm. Virtually any supervised learning algorithm could be used, such as decision trees, Naive Bayes , and rule induction. The genetic algorithm optimizes parameters for these heuristics with respect to performance on training documents with known key phrases.\n",
      "--------------------------------------\n",
      "Furthermore, training on a specific domain tends to customize the extraction process to that domain, so the resulting classifier is not necessarily portable, as some of Turney's results demonstrate. Recall this is based on the notion of \"prestige\" or \"recommendation\" from social networks . Unsupervised keyphrase extraction removes the need for training data.\n",
      "--------------------------------------\n",
      "For keyphrase extraction, it builds a graph using some set of text units as vertices. Essentially, it runs PageRank on a graph specially designed for a particular NLP task. Unlike PageRank, the edges are typically undirected and can be weighted to reflect a degree of similarity.\n",
      "--------------------------------------\n",
      "Potentially, we could do something similar to the supervised methods and create a vertex for each unigram, bigram, trigram, etc. Thus, some linguistic knowledge comes into play in this step. Note that the unigrams placed in the graph can be filtered by part of speech.\n",
      "--------------------------------------\n",
      "\"Natural\" and \"processing\" would also be linked because they would both appear in the same string of N words. Thus, \"natural\" and \"language\" might be linked in a text about NLP. Two vertices are connected by an edge if the unigrams appear within a window of size N in the original text.\n",
      "--------------------------------------\n",
      "As a result, potentially more or less than T final keyphrases will be produced, but the number should be roughly proportional to the length of the original text.  Since this method simply ranks the individual vertices, we need a way to threshold or produce a limited number of keyphrases. The technique chosen is to set a count T to be a user-specified fraction of the total number of vertices in the graph.\n",
      "--------------------------------------\n",
      "For example, in a text about machine learning, the unigram \"learning\" might co-occur with \"machine\", \"supervised\", \"un-supervised\", and \"semi-supervised\" in four different sentences. Similarly, if the text contains the phrase \"supervised classification\", then there would be an edge between \"supervised\" and \"classification\". In the final post-processing step, we would then end up with keyphrases \"supervised learning\" and \"supervised classification\".\n",
      "--------------------------------------\n",
      " In short, the co-occurrence graph will contain densely connected regions for terms that appear often and in different contexts. A random walk on this graph will have a stationary distribution that assigns large probabilities to the terms in the centers of the clusters. This is similar to densely connected Web pages getting ranked highly by PageRank.\n",
      "--------------------------------------\n",
      "The only real difference is that now we are dealing with larger text units—whole sentences instead of words and phrases.  Like keyphrase extraction, document summarization aims to identify the essence of a text.\n",
      "--------------------------------------\n",
      "For example, ROUGE-1 is computed as division of count of unigrams in reference that appear in system and count of unigrams in reference summary. Recall can be computed with respect to unigram, bigram, trigram, or 4-gram matching. This is a recall-based measure that determines how well a system-generated summary covers the content present in one or more human-generated model summaries known as references.\n",
      "--------------------------------------\n",
      "Note that ROUGE is similar to the BLEU measure for machine translation, but BLEU is precision- based, because translation systems favor accuracy.  If there are multiple references, the ROUGE-1 scores are averaged. High-order n-gram ROUGE measures try to judge fluency to some degree.\n",
      "--------------------------------------\n",
      "The idea of adaptive summarization involves preliminary recognition of document/text genre and subsequent application of summarization algorithms optimized for this genre.  A promising line in document summarization is adaptive document/text summarization. First summarizes that perform adaptive summarization have been created.\n",
      "--------------------------------------\n",
      "Features might include the position in the document (i.e., the first few sentences are probably important), the number of words in the sentence, etc. Note, however, that these natural summaries can still be used for evaluation purposes, since ROUGE-1 only cares about unigrams. Basically, if you have a collection of documents and human-generated summaries for them, you can learn features of sentences that make them good candidates for inclusion in the summary.\n",
      "--------------------------------------\n",
      " During the DUC 2001 and 2002 evaluation workshops, TNO developed a sentence extraction system for multi-document summarization in the news domain. The system was based on a hybrid system using a naive Bayes classifier and statistical language models for modeling salience. Maximum entropy has also been applied successfully for summarization in the broadcast news domain.\n",
      "--------------------------------------\n",
      "Some unsupervised summarization approaches are based on finding a \" centroid \" sentence, which is the mean word vector of all the sentences in the document.  The unsupervised approach to summarization is also quite similar in spirit to unsupervised keyphrase extraction and gets around the issue of costly training data. Then the sentences can be ranked with regard to their similarity to this centroid sentence.\n",
      "--------------------------------------\n",
      "LexRank is an algorithm essentially identical to TextRank, and both use this approach for document summarization.  A more principled way to estimate sentence importance is using random walks and eigenvector centrality.\n",
      "--------------------------------------\n",
      " In both LexRank and TextRank, a graph is constructed by creating a vertex for each sentence in the document.\n",
      "--------------------------------------\n",
      "The LexRank paper explored using unweighted edges after applying a threshold to the cosine values, but also experimented with using edges with weights equal to the similarity score.  The edges between sentences are based on some form of semantic similarity or content overlap. TextRank uses continuous similarity scores as weights.\n",
      "--------------------------------------\n",
      "A summary is formed by combining the top ranking sentences, using a threshold or length cutoff to limit the size of the summary.  In both algorithms, the sentences are ranked by applying PageRank to the resulting graph.\n",
      "--------------------------------------\n",
      "In this case, some training documents might be needed, though the TextRank results show the additional features are not absolutely necessary.\n",
      "--------------------------------------\n",
      "However, when summarizing multiple documents, there is a greater risk of selecting duplicate or highly redundant sentences to place in the same summary. Each article is likely to have many similar sentences, and you would only want to include distinct ideas in the summary. Imagine you have a cluster of news articles on a particular event, and you want to produce one summary.\n",
      "--------------------------------------\n",
      "Thus, to get ranked highly and placed in a summary, a sentence must be similar to many sentences that are in turn also similar to many other sentences. Thus, if one sentence is very similar to many others, it will likely be a sentence of great importance.  These methods work based on the idea that sentences \"recommend\" other similar sentences to the reader.\n",
      "--------------------------------------\n",
      "Resulting summary report allows individual users, such as professional information consumers, to quickly familiarize themselves with information contained in a large cluster of documents. In such a way, multi-document summarization systems are complementing the news aggregators performing the next step down the road of coping with information overload .  Multi-document summarization is an automatic procedure aimed at extraction of information from multiple texts written about the same topic.\n",
      "--------------------------------------\n",
      "Automatic summaries present information extracted from multiple sources algorithmically, without any editorial touch or subjective human intervention, thus making it completely unbiased. With different opinions being put together and outlined, every topic is described from multiple perspectives within a single document.  Multi-document summarization creates information reports that are both concise and comprehensive.\n",
      "--------------------------------------\n",
      "Ideally, we would like to extract sentences that are both \"central\" (i.e., contain the main ideas) and \"diverse\" (i.e., they differ from one another). There is a general purpose graph-based ranking algorithm like Page/Lex/TextRank that handles both \"centrality\" and \"diversity\" in a unified mathematical framework based on absorbing Markov chain random walks. In addition to explicitly promoting diversity during the ranking process, GRASSHOPPER incorporates a prior ranking (based on sentence position in the case of summarization).\n",
      "--------------------------------------\n",
      " The state of the art results for multi-document summarization, however, are obtained using mixtures of submodular functions. Similar results were also achieved with the use of determinantal point processes (which are a special case of submodular functions) for DUC-04. These methods have achieved the state of the art results for Document Summarization Corpora, DUC 04 - 07.\n",
      "--------------------------------------\n",
      "The Simplish Simplifying &amp; Summarizing tool - performs just such an automatic multi-lingual multi-document summarization.\n",
      "--------------------------------------\n",
      "For example, the set cover problem is a special case of submodular optimization, since the set cover function is submodular. Moreover, submodular functions can be efficiently combined together, and the resulting function is still submodular. Submodular functions naturally model notions of coverage , information , representation and diversity .\n",
      "--------------------------------------\n",
      "Moreover, the greedy algorithm is extremely simple to implement and can scale to large datasets, which is very important for summarization problems.  While submodular functions are fitting problems for summarization, they also admit very efficient algorithms for optimization. For example, a simple greedy algorithm admits a constant factor guarantee.\n",
      "--------------------------------------\n",
      "For example, work by Lin and Bilmes, 2012 shows that submodular functions achieve the best results to date on DUC-04, DUC-05, DUC-06 and DUC-07 systems for document summarization. Similarly, work by Lin and Bilmes, 2011, shows that many existing systems for automatic summarization are instances of submodular functions. This was a breakthrough result establishing submodular functions as the right models for summarization problems.\n",
      "--------------------------------------\n",
      "Similarly, Bairi et al., 2015 show the utility of submodular functions for summarizing multi-document topic hierarchies. Tschiatschek et al., 2014 show that mixtures of submodular functions achieve state-of-the-art results for image collection summarization. Submodular Functions have also successfully been used for summarizing machine learning datasets.\n",
      "--------------------------------------\n",
      " Specific applications of automatic summarization include:\n",
      "--------------------------------------\n",
      " The most common way to evaluate the informativeness of automatic summaries is to compare them with human-made model summaries.\n",
      "--------------------------------------\n",
      " Evaluation techniques fall into intrinsic and extrinsic, inter-textual and intra-textual.\n",
      "--------------------------------------\n",
      "Extrinsic evaluations, on the other hand, have tested the impact of summarization on tasks like relevance assessment, reading comprehension, etc. Intrinsic evaluations have assessed mainly the coherence and informativeness of summaries.\n",
      "--------------------------------------\n",
      " Intra-textual methods assess the output of a specific summarization system, and the inter-textual ones focus on contrastive analysis of outputs of several summarization systems.\n",
      "--------------------------------------\n",
      " Human judgement often has wide variance on what is considered a \"good\" summary, which means that making the evaluation process automatic is particularly difficult. Manual evaluation can be used, but this is both time and labor-intensive as it requires humans to read not only the summaries but also the source documents. Other issues are those concerning coherence and coverage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Similarly, for image summarization, Tschiatschek et al., developed a Visual-ROUGE score which judges the performance of algorithms for image summarization. A high level of overlap should indicate a high level of shared concepts between the two summaries. It essentially calculates n-gram overlaps between automatically generated summaries and previously-written human summaries.\n",
      "--------------------------------------\n",
      "For example, automatic summarization research on medical text generally attempts to utilize the various sources of codified medical knowledge and ontologies. Recent research focus has drifted to domain-specific summarization techniques that utilize the available knowledge specific to the domain of text.  Domain independent summarization techniques generally apply sets of general features which can be used to identify information-rich text segments.\n",
      "--------------------------------------\n",
      "In any case, what the evaluation methods need as an input, is a set of summaries to serve as gold standards and a set of automatic summaries. Furthermore, for some methods, not only do we need to have human-made summaries available for comparison, but also manual annotation has to be performed in some of them (e.g. Moreover, they all perform a quantitative evaluation with regard to different similarity metrics.\n"
     ]
    }
   ],
   "source": [
    "g = 1\n",
    "n = 3\n",
    "for gh in ggg:\n",
    "    sentence = nltk.sent_tokenize(gh)\n",
    "    word_frequency = find_word_frequency(gh)\n",
    "    sentence_scores_neu = sentence_scores(sentence, word_frequency)\n",
    "    summary_sentences = rank(sentence_scores_neu, n)\n",
    "    summary_of_paragraph = ' '.join(summary_sentences) \n",
    "    print(\"--------------------------------------\")\n",
    "    print(summary_of_paragraph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For example, in a text about machine learning, the unigram \"learning\" might co-occur with \"machine\", \"supervised\", \"un-supervised\", and \"semi-supervised\" in four different sentences. Consider the example text from a news article: ', ' A keyphrase extractor might select \"Army Corps of Engineers\", \"President Bush\", \"New Orleans\", and \"defective flood-control pumps\" as keyphrases. The first is generic summarization , which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). Given a document, we construct an example for each unigram , bigram , and trigram found in the text (though other text units are also possible, as discussed below). For example, work by Lin and Bilmes, 2012 shows that submodular functions achieve the best results to date on DUC-04, DUC-05, DUC-06 and DUC-07 systems for document summarization. Ideally, we would like to extract sentences that are both \"central\" (i.e., contain the main ideas) and \"diverse\" (i.e., they differ from one another). Extrinsic evaluations, on the other hand, have tested the impact of summarization on tasks like relevance assessment, reading comprehension, etc. For example, if we use only unigrams, bigrams, and trigrams, then we will never be able to extract a known keyphrase containing four words. Potentially, we could do something similar to the supervised methods and create a vertex for each unigram, bigram, trigram, etc. ', ' The state of the art results for multi-document summarization, however, are obtained using mixtures of submodular functions.\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "sentence = nltk.sent_tokenize(str(ggg))\n",
    "word_frequency = find_word_frequency(str(ggg))\n",
    "sentence_scores_neu = sentence_scores(sentence, word_frequency)\n",
    "neu_summary_sentences = rank(sentence_scores_neu, n)\n",
    "summary = ' '.join(neu_summary_sentences)  \n",
    "print(summary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
